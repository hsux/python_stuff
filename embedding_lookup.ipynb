{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding lookup sparse\n",
    "\n",
    "https://www.jianshu.com/p/f54eb9715609\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/94212544\n",
    "\n",
    "tf.nn.embedding_lookup_sparse(\n",
    "    params,\n",
    "    sp_ids,\n",
    "    sp_weights,\n",
    "    partition_strategy='mod',\n",
    "    name=None,\n",
    "    combiner=None,\n",
    "    max_norm=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_2:0' shape=(6, 4) dtype=float32_ref>\n",
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11.]\n",
      " [12. 13. 14. 15.]\n",
      " [16. 17. 18. 19.]\n",
      " [20. 21. 22. 23.]]\n"
     ]
    }
   ],
   "source": [
    "### embedding matrix\n",
    "example = np.arange(24).reshape(6, 4).astype(np.float32)\n",
    "embedding = tf.Variable(example)\n",
    "print(embedding)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x2b40c189a58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### embedding lookup SparseTensor 定义稀疏矩阵\n",
    "idx = tf.SparseTensor(indices=[[0, 0], [0, 1], [1, 1], [1, 2], [2, 0]],\n",
    "                      values=[0, 1, 2, 3, 0], dense_shape=[3, 3])\n",
    "# 这个稀疏矩阵写成普通形式这样\n",
    "#---------------------------------------------------------------------#\n",
    "#array([[0, 1, None],\n",
    "#       [None, 2, 3],\n",
    "#       [0, None, None]]) # 为了与0元素相区别，没有填充的部分写成了None\n",
    "#---------------------------------------------------------------------#\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup_sparse_1:0\", shape=(?, 4), dtype=float32)\n",
      "(3, 4)\n",
      "[[ 4.  6.  8. 10.]\n",
      " [20. 22. 24. 26.]\n",
      " [ 0.  1.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "embed = tf.nn.embedding_lookup_sparse(embedding, idx, None, combiner='sum')\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "emb = sess.run(embed)\n",
    "print(embed)\n",
    "print(emb.shape)\n",
    "print(emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果的shape=(idx.shape[0], embedding.shape[1])，其中结果的第一行等于“embeding的第一行加上embedding的第二行，也就是idx的第一行非None的元素的value，对应了embedding的行数，然后这些行相加“；结果第二行为”embedding第3行和第四行相加“；结果第三行也同理。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding lookup\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/93846683\n",
    "\n",
    "tf.nn.embedding_lookup(\n",
    "    params,\n",
    "    ids,\n",
    "    partition_strategy='mod',\n",
    "    name=None,\n",
    "    validate_indices=True,\n",
    "    max_norm=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"params_6:0\", shape=(3, 10), dtype=float32)\n",
      "Tensor(\"ids_5:0\", shape=(2, 4), dtype=int32)\n",
      "(2, 4, 10)\n",
      "[[[0.1 0.4 0.5 7.  6.4 1.2 0.5 0.3 3.3 2. ]\n",
      "  [0.4 0.9 1.1 4.3 3.4 0.2 0.3 0.2 0.5 0.1]\n",
      "  [0.1 0.4 0.5 7.  6.4 1.2 0.5 0.3 3.3 2. ]\n",
      "  [0.3 0.4 0.9 0.8 0.5 0.3 0.7 0.5 0.8 3.2]]\n",
      "\n",
      " [[0.1 0.4 0.5 7.  6.4 1.2 0.5 0.3 3.3 2. ]\n",
      "  [0.1 0.4 0.5 7.  6.4 1.2 0.5 0.3 3.3 2. ]\n",
      "  [0.3 0.4 0.9 0.8 0.5 0.3 0.7 0.5 0.8 3.2]\n",
      "  [0.3 0.4 0.9 0.8 0.5 0.3 0.7 0.5 0.8 3.2]]]\n",
      "Tensor(\"ids_vec_4:0\", shape=(4, 1), dtype=int32)\n",
      "(4, 1, 10)\n",
      "[[[0.1 0.4 0.5 7.  6.4 1.2 0.5 0.3 3.3 2. ]]\n",
      "\n",
      " [[0.4 0.9 1.1 4.3 3.4 0.2 0.3 0.2 0.5 0.1]]\n",
      "\n",
      " [[0.1 0.4 0.5 7.  6.4 1.2 0.5 0.3 3.3 2. ]]\n",
      "\n",
      " [[0.3 0.4 0.9 0.8 0.5 0.3 0.7 0.5 0.8 3.2]]]\n"
     ]
    }
   ],
   "source": [
    "params = tf.constant([[0.1, 0.4, 0.5, 7.0, 6.4, 1.2, 0.5, 0.3, 3.3, 2.0],\n",
    "                      [0.3, 0.4, 0.9, 0.8, 0.5, 0.3, 0.7, 0.5, 0.8, 3.2],\n",
    "                      [0.4, 0.9, 1.1, 4.3, 3.4, 0.2, 0.3, 0.2, 0.5, 0.1]],name='params')\n",
    "ids = tf.constant([[0, 2, 0, 1], [0, 0, 1, 1]],name='ids')\n",
    "ids_vec = tf.constant([[0], [2], [0], [1]],name='ids_vec')\n",
    "with tf.Session() as sess:\n",
    "    lookup = sess.run(tf.nn.embedding_lookup(params, ids))\n",
    "    vec_lookup = sess.run(tf.nn.embedding_lookup(params, ids_vec))\n",
    "\n",
    "\n",
    "print(params)\n",
    "print(ids)\n",
    "print(lookup.shape)\n",
    "print(lookup)\n",
    "print(ids_vec)\n",
    "print(vec_lookup.shape)\n",
    "print(vec_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.arange(60).reshape(3,4,5).astype(np.float32)  # [bs, feat_num, emb_dim]  feat_num=m\n",
    "emb = tf.Variable(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'split_1:0' shape=(3, 4, 1) dtype=float32>,\n",
       " <tf.Tensor 'split_1:1' shape=(3, 4, 1) dtype=float32>,\n",
       " <tf.Tensor 'split_1:2' shape=(3, 4, 1) dtype=float32>,\n",
       " <tf.Tensor 'split_1:3' shape=(3, 4, 1) dtype=float32>,\n",
       " <tf.Tensor 'split_1:4' shape=(3, 4, 1) dtype=float32>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_tensor0 = tf.split(emb, 5 * [1], 2)\n",
    "split_tensor0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.matmul(split_tensor0,split_tensor0,transpose_b=True)  # (emb_dim,bs,feat_num,feat_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_2:0' shape=(5, 3, 4, 4) dtype=float32>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=sess.run(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_1:0' shape=(3, 5, 16) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = tf.reshape(m,shape=[5,-1,4*4])\n",
    "o = tf.transpose(o, perm=[1, 0, 2])  # [bs, emb_dim, H_1*m]\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't split scalars for 'split_6' (op: 'SplitV') with input shapes: [], [5], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32md:\\python\\anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1606\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1607\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1608\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Can't split scalars for 'split_6' (op: 'SplitV') with input shapes: [], [5], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-5e1f4edf59d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python\\anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(value, num_or_size_splits, axis, num, name)\u001b[0m\n\u001b[0;32m   1697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1698\u001b[0m   return gen_array_ops.split_v(\n\u001b[1;32m-> 1699\u001b[1;33m       value=value, size_splits=size_splits, axis=axis, num_split=num, name=name)\n\u001b[0m\u001b[0;32m   1700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36msplit_v\u001b[1;34m(value, size_splits, axis, num_split, name)\u001b[0m\n\u001b[0;32m   9972\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   9973\u001b[0m         \u001b[1;34m\"SplitV\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9974\u001b[1;33m                   num_split=num_split, name=name)\n\u001b[0m\u001b[0;32m   9975\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9976\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[0;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m       \u001b[1;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32md:\\python\\anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3355\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[1;32m-> 3357\u001b[1;33m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[0;32m   3358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3359\u001b[0m   def _create_op_internal(\n",
      "\u001b[1;32md:\\python\\anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3426\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3428\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1770\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1771\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1608\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can't split scalars for 'split_6' (op: 'SplitV') with input shapes: [], [5], []."
     ]
    }
   ],
   "source": [
    "tf.split(0, 5 * [1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.],\n",
       "        [ 5.],\n",
       "        [10.],\n",
       "        [15.]],\n",
       "\n",
       "       [[20.],\n",
       "        [25.],\n",
       "        [30.],\n",
       "        [35.]],\n",
       "\n",
       "       [[40.],\n",
       "        [45.],\n",
       "        [50.],\n",
       "        [55.]]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(split_tensor0[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv1d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.arange(3*4*25).reshape(3,4,5*5).astype(np.float32)  # [bs, emb_dim, f*f]  feat_num=m\n",
    "emb = tf.Variable(e)  # [3,4,25]\n",
    "f = np.arange(1*25*7).reshape(1,25,7).astype(np.float32)  # [1, feat_num*feat_num, H_k]  feat_num=m\n",
    "fil = tf.Variable(f)  # [1,25,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = tf.nn.conv1d(emb,fil,stride=1,padding='VALID')  # [bs, emb_dim, H_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv1d/Squeeze:0' shape=(3, 4, 7) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.random.random([10,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\anaconda3\\envs\\tf15\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "    random_shifts = np.random.random(table.shape)\n",
    "    random_shifts /= random_shifts.sum(axis = 1)[:,np.newaxis]\n",
    "    result = []\n",
    "    for i in range(10):\n",
    "        table[i] /= table[i].sum()\n",
    "        shifted_probabilities = random_shifts[i] - table[i]\n",
    "        \n",
    "        l = np.argpartition(shifted_probabilities, 1, axis=0)[0]\n",
    "        table[i:,l] = 0\n",
    "        result.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
